{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20288b73-623c-4de4-a52d-fbe7d866edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- First 5 Rows ----\n",
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156  08-11-2016  11-11-2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156  08-11-2016  11-11-2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688  12-06-2016  16-06-2016    Second Class    DV-13045   \n",
      "3       4  US-2015-108966  11-10-2015  18-10-2015  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966  11-10-2015  18-10-2015  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600      2000   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "---- Data Types ----\n",
      "Row ID             int64\n",
      "Order ID          object\n",
      "Order Date        object\n",
      "Ship Date         object\n",
      "Ship Mode         object\n",
      "Customer ID       object\n",
      "Customer Name     object\n",
      "Segment           object\n",
      "Country           object\n",
      "City              object\n",
      "State             object\n",
      "Postal Code        int64\n",
      "Region            object\n",
      "Product ID        object\n",
      "Category          object\n",
      "Sub-Category      object\n",
      "Product Name      object\n",
      "Sales            float64\n",
      "Quantity           int64\n",
      "Discount         float64\n",
      "Profit           float64\n",
      "dtype: object\n",
      "\n",
      "Dataset Dimensions: 9994 rows, 21 columns\n",
      "\n",
      "---- Missing Values ----\n",
      "Row ID           0\n",
      "Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "Quantity         0\n",
      "Discount         0\n",
      "Profit           0\n",
      "dtype: int64\n",
      "\n",
      "---- Summary Statistics ----\n",
      "            Row ID   Postal Code         Sales     Quantity     Discount  \\\n",
      "count  9994.000000   9994.000000   9994.000000  9994.000000  9994.000000   \n",
      "mean   4997.500000  55190.379428    229.858001     3.989494     0.156203   \n",
      "std    2885.163629  32063.693350    623.245101    20.091679     0.206452   \n",
      "min       1.000000   1040.000000      0.444000     1.000000     0.000000   \n",
      "25%    2499.250000  23223.000000     17.280000     2.000000     0.000000   \n",
      "50%    4997.500000  56430.500000     54.490000     3.000000     0.200000   \n",
      "75%    7495.750000  90008.000000    209.940000     5.000000     0.200000   \n",
      "max    9994.000000  99301.000000  22638.480000  2000.000000     0.800000   \n",
      "\n",
      "            Profit  \n",
      "count  9994.000000  \n",
      "mean     28.656896  \n",
      "std     234.260108  \n",
      "min   -6599.978000  \n",
      "25%       1.728750  \n",
      "50%       8.666500  \n",
      "75%      29.364000  \n",
      "max    8399.976000  \n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Phase 1: Data Loading & Initial Inspection\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Downloads\\\\orders1.csv\")\n",
    "\n",
    "#Display the first few rows to understand the structure\n",
    "print(\"---- First 5 Rows ----\")\n",
    "print(df.head())\n",
    "\n",
    "#Display data types of each column\n",
    "print(\"\\n---- Data Types ----\")\n",
    "print(df.dtypes)\n",
    "\n",
    "#Print dataset dimensions\n",
    "print(f\"\\nDataset Dimensions: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "#Check for missing values in each column\n",
    "print(\"\\n---- Missing Values ----\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Basic descriptive statistics for numerical columns\n",
    "print(\"\\n---- Summary Statistics ----\")\n",
    "print(df.describe())\n",
    "\n",
    "#Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate Rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36e0709c-8218-4682-86f7-5aaa5b34598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dates converted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Data Cleaning\n",
    "\n",
    "\n",
    "#Convert 'Order Date' and 'Ship Date' to datetime using the correct format\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d-%m-%Y', errors='coerce')\n",
    "df['Ship Date'] = pd.to_datetime(df['Ship Date'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "#Verify that date conversion did not produce NaT values (if there are any errors in this, they will appear in the output:)\n",
    "if df['Order Date'].isnull().any() or df['Ship Date'].isnull().any():\n",
    "    print(\"\\nDate conversion errors detected. Please check the date format in your CSV.\")\n",
    "else:\n",
    "    print(\"\\nDates converted successfully.\")\n",
    "\n",
    "#Fill missing values\n",
    "#FOR EXAMPLE: For Postal Code, fill missing values with the mode (most frequent value)\n",
    "if df['Postal Code'].isnull().sum() > 0:\n",
    "    df['Postal Code'].fillna(df['Postal Code'].mode()[0], inplace=True)\n",
    "\n",
    "#Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "#Standardize text columns for consistency (it converts to title case and strip extra spaces)\n",
    "for col in ['Customer Name', 'City', 'State', 'Country']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.title().str.strip()\n",
    "\n",
    "#Handle outliers in numerical columns (Sales and Profit) using winsorization(capping)\n",
    "def cap_outliers(series, lower_quantile=0.05, upper_quantile=0.95):\n",
    "    lower = series.quantile(lower_quantile)\n",
    "    upper = series.quantile(upper_quantile)\n",
    "    return np.clip(series, lower, upper)\n",
    "\n",
    "df['Sales'] = cap_outliers(df['Sales'])\n",
    "df['Profit'] = cap_outliers(df['Profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12fadf7f-615b-4a21-bd39-5178487f591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Total Sales per Customer (Sample) ----\n",
      "  Customer ID  Total Sales\n",
      "0    AA-10315  2593.148245\n",
      "1    AA-10375  1056.390000\n",
      "2    AA-10480  1790.512000\n",
      "3    AA-10645  4397.838490\n",
      "4    AB-10015   886.156000\n",
      "\n",
      "---- Average Discount by Category (Sample) ----\n",
      "          Category  Average Discount\n",
      "0        Furniture          0.173923\n",
      "1  Office Supplies          0.157285\n",
      "2       Technology          0.132323\n",
      "\n",
      "---- Normalized Profit (First 5 Rows) ----\n",
      "      Profit  Normalized Profit\n",
      "0   41.91360           0.428641\n",
      "1  168.47040           1.000000\n",
      "2    6.87140           0.270438\n",
      "3  -53.03092           0.000000\n",
      "4    2.51640           0.250776\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Data Transformation\n",
    "# ============================\n",
    "\n",
    "# Feature Engineering: Create a new column for 'Processing Time' (in days)\n",
    "df['Processing Time'] = (df['Ship Date'] - df['Order Date']).dt.days\n",
    "\n",
    "# Feature Engineering: Create 'Revenue Category' based on the Sales column\n",
    "df['Revenue Category'] = pd.cut(df['Sales'],\n",
    "                                bins=[0, 100, 500, 1000, 5000, np.inf],\n",
    "                                labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Data Aggregation: Calculate total sales per customer\n",
    "customer_sales = df.groupby('Customer ID')['Sales'].sum().reset_index()\n",
    "customer_sales.rename(columns={'Sales': 'Total Sales'}, inplace=True)\n",
    "print(\"\\n---- Total Sales per Customer (Sample) ----\")\n",
    "print(customer_sales.head())\n",
    "\n",
    "# Data Aggregation: Calculate average discount by product category\n",
    "category_discount = df.groupby('Category')['Discount'].mean().reset_index()\n",
    "category_discount.rename(columns={'Discount': 'Average Discount'}, inplace=True)\n",
    "print(\"\\n---- Average Discount by Category (Sample) ----\")\n",
    "print(category_discount.head())\n",
    "\n",
    "# Data Standardization/Normalization: Normalize the 'Profit' column (keeping Sales unchanged for Revenue Category)\n",
    "scaler = MinMaxScaler()\n",
    "df['Normalized Profit'] = scaler.fit_transform(df[['Profit']])\n",
    "print(\"\\n---- Normalized Profit (First 5 Rows) ----\")\n",
    "print(df[['Profit', 'Normalized Profit']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7aa0703-b164-4ab7-90d9-07fba7ca0ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset saved to: /mnt/data/cleaned_orders.csv\n"
     ]
    }
   ],
   "source": [
    "#Phase 4: Reporting & Documentation\n",
    "\n",
    "\n",
    "#create the directory first\n",
    "import os\n",
    "os.makedirs(\"/mnt/data\", exist_ok=True)\n",
    "#save the cleaned and transformed dataset to a new CSV file\n",
    "output_path = \"/mnt/data/cleaned_orders.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nCleaned dataset saved to: {output_path}\")\n",
    "\n",
    "#Report Summary:\n",
    "# 1.Loaded the dataset and inspected its structure.\n",
    "# 2.Converted date columns and handled missing values.\n",
    "# 3.Removed duplicates and standardized text fields.\n",
    "# 4.Handled outliers in Sales and Profit using winsorization.\n",
    "# 5.Engineered features (Processing Time, Revenue Category) and aggregated data for insights.\n",
    "# 6.Normalized the Profit column for additional analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
